{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "Packages we (might) use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DrWatson\n",
    "@quickactivate \"SMLP2020\"\n",
    "\n",
    "using MixedModels\n",
    "using CSV, DataFrames, DataFramesMeta, RCall \n",
    "using Statistics: mean, var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specification\n",
    "\n",
    "## Response, covariates, and factors\n",
    "\n",
    "Linear mixed models (LMMs), like many other types of statistical models, describe a relationship between a *response* variable and *covariates* that have been measured or observed along with the response. The statistical model assumes that the residuals of the fitted response (i.e., not the responses) are normally -- also identically and independently -- distributed. This is the *first assumption* of normality in the LMM. It is standard practice that model residuals are inspected and, if serious skew is indicated, that the response is Box-Cox transformed (unless not justified for theoretical reasons) to fulfill this model assumption. \n",
    "\n",
    "In the following we distinguish between *categorical covariates* and *numerical covariates*. Categorical covariates are  *factors*. The important characteristic of a factor is that, for each observed value of the response, the factor takes on the value of one of a set of discrete levels.  The levels can be unordered (nominal) or ordered (ordinal). We use the term *covariate* when we refer to *numerical covariates*, that is to continuous measures with some distribution. In principle, statistical models are not constrained by the distribution of observations across levels of factors and covariates, but the distribution may lead to problems of model identification and it does implications for statistical power. \n",
    "\n",
    "Statistical power, especially for the detection of interactions, is best when observations are uniformly distributed across levels of factors or uniform across the values of covariates. In experimental designs, uniform distributions may be achieved by balanced assignment of subjects (or other carriers of responses) to the levels of factors or combinations of factor levels. In observational contexts, we achieve uniform distributions by stratification (e..g., on age, gender, or IQ scores). Statistical power is worse for skewed than normal distributions (I think ...). Therefore, although it is *not* required to meet an assumption of the statistical model, it may be useful to consider Box-Cox transformations of covariates.\n",
    "\n",
    "## Nested and crossed random (grouping) factors\n",
    "\n",
    "In LMMs the levels of at least one of the factors represents *units* in the data set that are assumed to be sampled, ideally randomly, from a population that is normally distributed with respect to the response. *This is the second assumption of normal distribution in LMMs.*  In psychology and linguistics the observational units are often the subjects or items (e..g., texts, sentences, words, pictures) in the study. We may use numbers, such as subject identifiers, to designate the particular levels that we observed; we recommend to prepend these numbers with \"S\" or \"I\" to avoid confusion with numeric variables.\n",
    "\n",
    "Random sampling is the basis of generalization from the sample to the population. The core statistics we will estimate in this context are variances and correlations of grand means and (quasi-)experimental effects. These terms will be explained below. What we want to stress here is that the estimation of (co-)variances / correlations requires a larger number of units (levels) than the estimation of means. Therefore, from a practical perspective, it is important that random factors are represented with many units.\n",
    "\n",
    "When there is more than one random factor, we must be clear about their relation. The two prototypical cases are that the factors are *nested* or *crossed*.  In multilevel models, a special case of mixed models, the levels of the random factors are strictly nested. For example, at a given time, every student attends a specific class in a specific school. Students, classes, and schools could be three random factors. As soon as we look at this scenario across several school years, the nesting quickly falls apart because students may move between classes and between schools. \n",
    "\n",
    "In psychology and linguistics, random factors are often crossed, for example, when every subject reads every word in every sentence in a word-by-word self-paced reading experiment (or alternatively: when every word in every sentence elicits a response from every subject). However, in an eye-movement experiment (for example), the perfect crossing on a measure like fixation duration is not attainable because of blinks or skipping of words.\n",
    "\n",
    "In summary, the typical situation in experimental and observational studies with more than one random factor is _partial crossing_ or _partial nesting_ of levels of the random factors. Linear mixed models handle these situations very well. \n",
    "\n",
    "## Experimental and quasi-experimental fixed factors / covariates\n",
    "\n",
    "*Fixed experimental factor or covariate*. In experiments the units (or levels) of the random factor(s) are assigned to manipulations implemented in their design. The researcher controls the assignment of units of the random factor(s) (e.g., subjects, items) to experimental manipulations. These manipulations are represented as factors with a fixed and discrete set of levels (e.g., training vs. control group) or as covariates associated with continuous numeric values (e.g., presentation times). \n",
    "\n",
    "*Fixed quasi-experimental factor or covariate*. In observational studies (which can also be experiments) the units (or levels) of random factors may \"bring along\" characteristics that represent the levels of quasi-experimental factors or covariates beyond the control of the researcher. Whether a a subject is female, male, or diverse or whether a word is a noun, a verb, or an adjective are examples of quasi-experimental factors of gender or word type, respectively. Subject-related covariates are body height, body mass, and IQ scores; word-related covariates are their lengths, frequency, and cloze predictability. \n",
    "\n",
    "## Between-unit and within-unit factors / covariates\n",
    "\n",
    "The distinction between between-unit and within-unit factors is always relative to a random (grouping) factor of an experimental design. A between-unit factor / covariate is a factor for which every unit of the random factor is assigned to or characterized by only one level of the factor. A within-unit factor is a factor for which units of the random factor appear at every level of the factor. \n",
    "\n",
    "For the typical random factor, say *Subject*, there is little ambiguity because we are used to the between-within distinction from ANOVAs, more specifically the F1-ANOVA. In psycholinguistics, there is the tradition to test effects also for the second random factor *Item* in an F2-ANOVA. Importantly, for a given fixed factor all four combinations are possible. For example, *Gender* is a fixed quasi-experimental between-subject / within-item factor; word frequency is a fixed quasi-experimental within-subject / between-item covariate; *Pime-target relation* is a fixed experimental  within-subject / within-item factor (assuming that targets are presented both in a primed and in an unprimed situation); and when a training manipulation is defined by the items used in the training, then in a training-control group design, the fixed factor *Group* is a fixed experimental between-subject / between-item factor.    \n",
    "\n",
    "These distinctions are critical for setting up LMMs because variance components for (quasi-)experimental effects can only be specified for within-unit effects. Note also that loss of data (within limits), counterbalancing or blocking of items are irrelevant for these definitions. \n",
    "\n",
    "## Factor-based contrasts and covariate-based trends\n",
    "\n",
    "The simplest fixed factor has two levels and the model estimates the difference between them. When we move to factors with *k*  levels, we must decide on how we *spend* the *k-1* degrees of freedom, that is we must specify a set of contrasts. (If we don't do it, the program chooses dummy contrasts for us.)\n",
    "\n",
    "The simplest specification of a covariate is to include its linear trend, that is its slope. The slope (like a contrast) represents a difference score, that is the change in response to a one-unit change on the covariate. For covariates we must decide on the order of the trend we want to model.\n",
    "\n",
    "## Contrast- and trend-based fixed-effect model parameters \n",
    "\n",
    "Fixed factors and covariates are expected to have effects on the response. Fixed-effect model parameters estimate the hypothesized main and interaction effects of the study. The estimates of factors are based on contrasts; the estimates of covariates are based on trends. Conceptually, they correspond to unstandardized regression coefficients in multiple regression. \n",
    "\n",
    "The intercept is a special regression coefficient; it estimates the value of the dependent variable when all fixed effects associated with factors and trends associated with covariates are zero. In experimental designs with higher order interactions there is an advantage of specifying the LMM in such a way that the intercept estimates the grand mean (GM). This happens if (a) contrasts for factors are chosen such that the intercept estimates the GM (positive: Sum, SeqDifference, or Helmert contrasts; negative: Dummy contrasts), (b) orthogonal polynomial trends are used (Helmert, anova-based), and (c) covariates are centered on their mean before inclusion in the model. As always, there may be good theoretical reasons to depart from the default recommendation. \n",
    "\n",
    "The specification of contrasts / trends does not depend on the status of the fixed factor / covariate. It does not matter whether a factor varies between or within the units of a random factor or whether it is an experimental or quasi-experimental factor. Contrasts are *not* specified for random (grouping) factors.\n",
    "\n",
    "## Variance components (VCs) and correlation parameters (CPs)\n",
    "\n",
    "Variance components (VCs) and correlation parameters (CPs) are within-group model parameters; they correspond to (some of the) *within-unit* (quasi-)experimental fixed-effect model parameters. Thus, we may be able to estimate a subject-related VC for word frequency. If we included a linear trend for word frequency, the VC estimates the subject-related variance in these slopes. We cannot estimate an item-related VC for the word-frequency slopes because there is only one frequency associated with words. Analogously, we may able to estimate an item-related VC for the effect of `Group (training vs. control)`, but we cannot estimate a subject-related VC for this effect. \n",
    "\n",
    "The within-between characteristics of fixed factors and covariates relative to the random factor(s) are features of the design of the experiment or observational study. They fundamentally constrain the specification of the LMM. That's why it is of upmost importance to be absolutely clear about their status.  \n",
    "\n",
    "## Conditional modes of random effects\n",
    "\n",
    "In this outline of the dimensions underlying the specification of an LMM, we have said nothing so far about the conditional modes of random effects (i.e., the results shown in caterpillar and shrinkage plots). They are not needed for model specification or model selection.  \n",
    "\n",
    "The VC is the prior variance of the random effects, whereas `var(ranef(model))` is the variance of the posterior means/modes of the random effects. See Kliegl et al. (2010, VisualCognition); [Rizopoulos (2019, stackexchange](https://stats.stackexchange.com/questions/392283/interpreting-blups-or-varcorr-estimates-in-mixed-models/392307#392307).\n",
    "\n",
    "# `MRK17_Exp1.rds` data \n",
    "\n",
    "## Preprocessing\n",
    "\n",
    "We read the data preprocessed with R and saved as RDS file (see `DataPrep.Rmd` for details)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>variable</th><th>mean</th><th>min</th><th>median</th><th>max</th><th>nunique</th><th>nmissing</th><th>eltype</th></tr><tr><th></th><th>Symbol</th><th>Union…</th><th>Any</th><th>Union…</th><th>Any</th><th>Union…</th><th>Nothing</th><th>DataType</th></tr></thead><tbody><p>9 rows × 8 columns</p><tr><th>1</th><td>Subj</td><td></td><td>S01</td><td></td><td>S73</td><td>73</td><td></td><td>CategoricalValue{String,UInt32}</td></tr><tr><th>2</th><td>Item</td><td></td><td>CAKE</td><td></td><td>THIEF</td><td>240</td><td></td><td>CategoricalValue{String,UInt32}</td></tr><tr><th>3</th><td>trial</td><td>239.958</td><td>2</td><td>239.0</td><td>480</td><td></td><td></td><td>Int64</td></tr><tr><th>4</th><td>F</td><td></td><td>LF</td><td></td><td>HF</td><td>2</td><td></td><td>CategoricalValue{String,UInt32}</td></tr><tr><th>5</th><td>P</td><td></td><td>unr</td><td></td><td>rel</td><td>2</td><td></td><td>CategoricalValue{String,UInt32}</td></tr><tr><th>6</th><td>Q</td><td></td><td>deg</td><td></td><td>clr</td><td>2</td><td></td><td>CategoricalValue{String,UInt32}</td></tr><tr><th>7</th><td>lQ</td><td></td><td>deg</td><td></td><td>clr</td><td>2</td><td></td><td>CategoricalValue{String,UInt32}</td></tr><tr><th>8</th><td>lT</td><td></td><td>NW</td><td></td><td>WD</td><td>2</td><td></td><td>CategoricalValue{String,UInt32}</td></tr><tr><th>9</th><td>rt</td><td>647.173</td><td>301</td><td>601.0</td><td>2994</td><td></td><td></td><td>Int64</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccc}\n",
       "\t& variable & mean & min & median & max & nunique & nmissing & eltype\\\\\n",
       "\t\\hline\n",
       "\t& Symbol & Union… & Any & Union… & Any & Union… & Nothing & DataType\\\\\n",
       "\t\\hline\n",
       "\t1 & Subj &  & S01 &  & S73 & 73 &  & CategoricalValue\\{String,UInt32\\} \\\\\n",
       "\t2 & Item &  & CAKE &  & THIEF & 240 &  & CategoricalValue\\{String,UInt32\\} \\\\\n",
       "\t3 & trial & 239.958 & 2 & 239.0 & 480 &  &  & Int64 \\\\\n",
       "\t4 & F &  & LF &  & HF & 2 &  & CategoricalValue\\{String,UInt32\\} \\\\\n",
       "\t5 & P &  & unr &  & rel & 2 &  & CategoricalValue\\{String,UInt32\\} \\\\\n",
       "\t6 & Q &  & deg &  & clr & 2 &  & CategoricalValue\\{String,UInt32\\} \\\\\n",
       "\t7 & lQ &  & deg &  & clr & 2 &  & CategoricalValue\\{String,UInt32\\} \\\\\n",
       "\t8 & lT &  & NW &  & WD & 2 &  & CategoricalValue\\{String,UInt32\\} \\\\\n",
       "\t9 & rt & 647.173 & 301 & 601.0 & 2994 &  &  & Int64 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "9×8 DataFrame. Omitted printing of 1 columns\n",
       "│ Row │ variable │ mean    │ min  │ median │ max   │ nunique │ nmissing │\n",
       "│     │ \u001b[90mSymbol\u001b[39m   │ \u001b[90mUnion…\u001b[39m  │ \u001b[90mAny\u001b[39m  │ \u001b[90mUnion…\u001b[39m │ \u001b[90mAny\u001b[39m   │ \u001b[90mUnion…\u001b[39m  │ \u001b[90mNothing\u001b[39m  │\n",
       "├─────┼──────────┼─────────┼──────┼────────┼───────┼─────────┼──────────┤\n",
       "│ 1   │ Subj     │         │ S01  │        │ S73   │ 73      │          │\n",
       "│ 2   │ Item     │         │ CAKE │        │ THIEF │ 240     │          │\n",
       "│ 3   │ trial    │ 239.958 │ 2    │ 239.0  │ 480   │         │          │\n",
       "│ 4   │ F        │         │ LF   │        │ HF    │ 2       │          │\n",
       "│ 5   │ P        │         │ unr  │        │ rel   │ 2       │          │\n",
       "│ 6   │ Q        │         │ deg  │        │ clr   │ 2       │          │\n",
       "│ 7   │ lQ       │         │ deg  │        │ clr   │ 2       │          │\n",
       "│ 8   │ lT       │         │ NW   │        │ WD    │ 2       │          │\n",
       "│ 9   │ rt       │ 647.173 │ 301  │ 601.0  │ 2994  │         │          │"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat = rcopy(R\"readRDS($datadir('MRK17_Exp1.rds'))\");\n",
    "describe(dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The levels of several factors are not in the desired order. We reorder factor levels such that the level with the expected slow response is the second level. This way the fixed effect will be estimated as a positive value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>F</th><th>P</th><th>Q</th><th>lQ</th><th>lT</th><th>meanRT</th><th>sdRT</th><th>n</th><th>semean</th></tr><tr><th></th><th>Cat…</th><th>Cat…</th><th>Cat…</th><th>Cat…</th><th>Cat…</th><th>Float64</th><th>Float64</th><th>Int64</th><th>Float64</th></tr></thead><tbody><p>32 rows × 9 columns</p><tr><th>1</th><td>HF</td><td>rel</td><td>clr</td><td>clr</td><td>WD</td><td>613.094</td><td>192.13</td><td>499</td><td>8.60094</td></tr><tr><th>2</th><td>HF</td><td>rel</td><td>clr</td><td>clr</td><td>NW</td><td>635.319</td><td>205.19</td><td>546</td><td>8.78134</td></tr><tr><th>3</th><td>HF</td><td>rel</td><td>clr</td><td>deg</td><td>WD</td><td>620.569</td><td>173.764</td><td>504</td><td>7.74007</td></tr><tr><th>4</th><td>HF</td><td>rel</td><td>clr</td><td>deg</td><td>NW</td><td>615.647</td><td>176.826</td><td>527</td><td>7.70268</td></tr><tr><th>5</th><td>HF</td><td>rel</td><td>deg</td><td>clr</td><td>WD</td><td>667.685</td><td>231.145</td><td>517</td><td>10.1657</td></tr><tr><th>6</th><td>HF</td><td>rel</td><td>deg</td><td>clr</td><td>NW</td><td>645.493</td><td>179.962</td><td>507</td><td>7.9924</td></tr><tr><th>7</th><td>HF</td><td>rel</td><td>deg</td><td>deg</td><td>WD</td><td>637.793</td><td>177.496</td><td>546</td><td>7.59611</td></tr><tr><th>8</th><td>HF</td><td>rel</td><td>deg</td><td>deg</td><td>NW</td><td>659.266</td><td>192.637</td><td>508</td><td>8.54688</td></tr><tr><th>9</th><td>HF</td><td>unr</td><td>clr</td><td>clr</td><td>WD</td><td>620.838</td><td>192.689</td><td>532</td><td>8.35414</td></tr><tr><th>10</th><td>HF</td><td>unr</td><td>clr</td><td>clr</td><td>NW</td><td>619.626</td><td>176.55</td><td>495</td><td>7.93533</td></tr><tr><th>11</th><td>HF</td><td>unr</td><td>clr</td><td>deg</td><td>WD</td><td>633.046</td><td>172.604</td><td>495</td><td>7.75799</td></tr><tr><th>12</th><td>HF</td><td>unr</td><td>clr</td><td>deg</td><td>NW</td><td>644.6</td><td>203.261</td><td>553</td><td>8.64355</td></tr><tr><th>13</th><td>HF</td><td>unr</td><td>deg</td><td>clr</td><td>WD</td><td>671.728</td><td>203.986</td><td>507</td><td>9.05932</td></tr><tr><th>14</th><td>HF</td><td>unr</td><td>deg</td><td>clr</td><td>NW</td><td>652.59</td><td>159.715</td><td>541</td><td>6.86668</td></tr><tr><th>15</th><td>HF</td><td>unr</td><td>deg</td><td>deg</td><td>WD</td><td>642.201</td><td>173.235</td><td>497</td><td>7.77066</td></tr><tr><th>16</th><td>HF</td><td>unr</td><td>deg</td><td>deg</td><td>NW</td><td>655.712</td><td>179.367</td><td>504</td><td>7.98966</td></tr><tr><th>17</th><td>LF</td><td>rel</td><td>clr</td><td>clr</td><td>WD</td><td>624.478</td><td>194.015</td><td>534</td><td>8.39585</td></tr><tr><th>18</th><td>LF</td><td>rel</td><td>clr</td><td>clr</td><td>NW</td><td>624.172</td><td>174.979</td><td>487</td><td>7.92906</td></tr><tr><th>19</th><td>LF</td><td>rel</td><td>clr</td><td>deg</td><td>WD</td><td>623.244</td><td>178.251</td><td>546</td><td>7.62842</td></tr><tr><th>20</th><td>LF</td><td>rel</td><td>clr</td><td>deg</td><td>NW</td><td>635.076</td><td>192.738</td><td>499</td><td>8.62812</td></tr><tr><th>21</th><td>LF</td><td>rel</td><td>deg</td><td>clr</td><td>WD</td><td>678.119</td><td>217.209</td><td>512</td><td>9.59937</td></tr><tr><th>22</th><td>LF</td><td>rel</td><td>deg</td><td>clr</td><td>NW</td><td>650.16</td><td>167.51</td><td>539</td><td>7.21516</td></tr><tr><th>23</th><td>LF</td><td>rel</td><td>deg</td><td>deg</td><td>WD</td><td>653.43</td><td>180.58</td><td>498</td><td>8.09199</td></tr><tr><th>24</th><td>LF</td><td>rel</td><td>deg</td><td>deg</td><td>NW</td><td>667.872</td><td>175.869</td><td>492</td><td>7.92878</td></tr><tr><th>25</th><td>LF</td><td>unr</td><td>clr</td><td>clr</td><td>WD</td><td>641.669</td><td>183.413</td><td>499</td><td>8.21068</td></tr><tr><th>26</th><td>LF</td><td>unr</td><td>clr</td><td>clr</td><td>NW</td><td>648.057</td><td>209.625</td><td>506</td><td>9.31899</td></tr><tr><th>27</th><td>LF</td><td>unr</td><td>clr</td><td>deg</td><td>WD</td><td>653.03</td><td>196.71</td><td>494</td><td>8.85042</td></tr><tr><th>28</th><td>LF</td><td>unr</td><td>clr</td><td>deg</td><td>NW</td><td>658.225</td><td>213.144</td><td>528</td><td>9.27592</td></tr><tr><th>29</th><td>LF</td><td>unr</td><td>deg</td><td>clr</td><td>WD</td><td>676.711</td><td>167.794</td><td>519</td><td>7.36535</td></tr><tr><th>30</th><td>LF</td><td>unr</td><td>deg</td><td>clr</td><td>NW</td><td>685.265</td><td>186.73</td><td>499</td><td>8.35916</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccccc}\n",
       "\t& F & P & Q & lQ & lT & meanRT & sdRT & n & semean\\\\\n",
       "\t\\hline\n",
       "\t& Cat… & Cat… & Cat… & Cat… & Cat… & Float64 & Float64 & Int64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & HF & rel & clr & clr & WD & 613.094 & 192.13 & 499 & 8.60094 \\\\\n",
       "\t2 & HF & rel & clr & clr & NW & 635.319 & 205.19 & 546 & 8.78134 \\\\\n",
       "\t3 & HF & rel & clr & deg & WD & 620.569 & 173.764 & 504 & 7.74007 \\\\\n",
       "\t4 & HF & rel & clr & deg & NW & 615.647 & 176.826 & 527 & 7.70268 \\\\\n",
       "\t5 & HF & rel & deg & clr & WD & 667.685 & 231.145 & 517 & 10.1657 \\\\\n",
       "\t6 & HF & rel & deg & clr & NW & 645.493 & 179.962 & 507 & 7.9924 \\\\\n",
       "\t7 & HF & rel & deg & deg & WD & 637.793 & 177.496 & 546 & 7.59611 \\\\\n",
       "\t8 & HF & rel & deg & deg & NW & 659.266 & 192.637 & 508 & 8.54688 \\\\\n",
       "\t9 & HF & unr & clr & clr & WD & 620.838 & 192.689 & 532 & 8.35414 \\\\\n",
       "\t10 & HF & unr & clr & clr & NW & 619.626 & 176.55 & 495 & 7.93533 \\\\\n",
       "\t11 & HF & unr & clr & deg & WD & 633.046 & 172.604 & 495 & 7.75799 \\\\\n",
       "\t12 & HF & unr & clr & deg & NW & 644.6 & 203.261 & 553 & 8.64355 \\\\\n",
       "\t13 & HF & unr & deg & clr & WD & 671.728 & 203.986 & 507 & 9.05932 \\\\\n",
       "\t14 & HF & unr & deg & clr & NW & 652.59 & 159.715 & 541 & 6.86668 \\\\\n",
       "\t15 & HF & unr & deg & deg & WD & 642.201 & 173.235 & 497 & 7.77066 \\\\\n",
       "\t16 & HF & unr & deg & deg & NW & 655.712 & 179.367 & 504 & 7.98966 \\\\\n",
       "\t17 & LF & rel & clr & clr & WD & 624.478 & 194.015 & 534 & 8.39585 \\\\\n",
       "\t18 & LF & rel & clr & clr & NW & 624.172 & 174.979 & 487 & 7.92906 \\\\\n",
       "\t19 & LF & rel & clr & deg & WD & 623.244 & 178.251 & 546 & 7.62842 \\\\\n",
       "\t20 & LF & rel & clr & deg & NW & 635.076 & 192.738 & 499 & 8.62812 \\\\\n",
       "\t21 & LF & rel & deg & clr & WD & 678.119 & 217.209 & 512 & 9.59937 \\\\\n",
       "\t22 & LF & rel & deg & clr & NW & 650.16 & 167.51 & 539 & 7.21516 \\\\\n",
       "\t23 & LF & rel & deg & deg & WD & 653.43 & 180.58 & 498 & 8.09199 \\\\\n",
       "\t24 & LF & rel & deg & deg & NW & 667.872 & 175.869 & 492 & 7.92878 \\\\\n",
       "\t25 & LF & unr & clr & clr & WD & 641.669 & 183.413 & 499 & 8.21068 \\\\\n",
       "\t26 & LF & unr & clr & clr & NW & 648.057 & 209.625 & 506 & 9.31899 \\\\\n",
       "\t27 & LF & unr & clr & deg & WD & 653.03 & 196.71 & 494 & 8.85042 \\\\\n",
       "\t28 & LF & unr & clr & deg & NW & 658.225 & 213.144 & 528 & 9.27592 \\\\\n",
       "\t29 & LF & unr & deg & clr & WD & 676.711 & 167.794 & 519 & 7.36535 \\\\\n",
       "\t30 & LF & unr & deg & clr & NW & 685.265 & 186.73 & 499 & 8.35916 \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "32×9 DataFrame\n",
       "│ Row │ F    │ P    │ Q    │ lQ   │ lT   │ meanRT  │ sdRT    │ n     │ semean  │\n",
       "│     │ \u001b[90mCat…\u001b[39m │ \u001b[90mCat…\u001b[39m │ \u001b[90mCat…\u001b[39m │ \u001b[90mCat…\u001b[39m │ \u001b[90mCat…\u001b[39m │ \u001b[90mFloat64\u001b[39m │ \u001b[90mFloat64\u001b[39m │ \u001b[90mInt64\u001b[39m │ \u001b[90mFloat64\u001b[39m │\n",
       "├─────┼──────┼──────┼──────┼──────┼──────┼─────────┼─────────┼───────┼─────────┤\n",
       "│ 1   │ HF   │ rel  │ clr  │ clr  │ WD   │ 613.094 │ 192.13  │ 499   │ 8.60094 │\n",
       "│ 2   │ HF   │ rel  │ clr  │ clr  │ NW   │ 635.319 │ 205.19  │ 546   │ 8.78134 │\n",
       "│ 3   │ HF   │ rel  │ clr  │ deg  │ WD   │ 620.569 │ 173.764 │ 504   │ 7.74007 │\n",
       "│ 4   │ HF   │ rel  │ clr  │ deg  │ NW   │ 615.647 │ 176.826 │ 527   │ 7.70268 │\n",
       "│ 5   │ HF   │ rel  │ deg  │ clr  │ WD   │ 667.685 │ 231.145 │ 517   │ 10.1657 │\n",
       "│ 6   │ HF   │ rel  │ deg  │ clr  │ NW   │ 645.493 │ 179.962 │ 507   │ 7.9924  │\n",
       "│ 7   │ HF   │ rel  │ deg  │ deg  │ WD   │ 637.793 │ 177.496 │ 546   │ 7.59611 │\n",
       "│ 8   │ HF   │ rel  │ deg  │ deg  │ NW   │ 659.266 │ 192.637 │ 508   │ 8.54688 │\n",
       "│ 9   │ HF   │ unr  │ clr  │ clr  │ WD   │ 620.838 │ 192.689 │ 532   │ 8.35414 │\n",
       "│ 10  │ HF   │ unr  │ clr  │ clr  │ NW   │ 619.626 │ 176.55  │ 495   │ 7.93533 │\n",
       "⋮\n",
       "│ 22  │ LF   │ rel  │ deg  │ clr  │ NW   │ 650.16  │ 167.51  │ 539   │ 7.21516 │\n",
       "│ 23  │ LF   │ rel  │ deg  │ deg  │ WD   │ 653.43  │ 180.58  │ 498   │ 8.09199 │\n",
       "│ 24  │ LF   │ rel  │ deg  │ deg  │ NW   │ 667.872 │ 175.869 │ 492   │ 7.92878 │\n",
       "│ 25  │ LF   │ unr  │ clr  │ clr  │ WD   │ 641.669 │ 183.413 │ 499   │ 8.21068 │\n",
       "│ 26  │ LF   │ unr  │ clr  │ clr  │ NW   │ 648.057 │ 209.625 │ 506   │ 9.31899 │\n",
       "│ 27  │ LF   │ unr  │ clr  │ deg  │ WD   │ 653.03  │ 196.71  │ 494   │ 8.85042 │\n",
       "│ 28  │ LF   │ unr  │ clr  │ deg  │ NW   │ 658.225 │ 213.144 │ 528   │ 9.27592 │\n",
       "│ 29  │ LF   │ unr  │ deg  │ clr  │ WD   │ 676.711 │ 167.794 │ 519   │ 7.36535 │\n",
       "│ 30  │ LF   │ unr  │ deg  │ clr  │ NW   │ 685.265 │ 186.73  │ 499   │ 8.35916 │\n",
       "│ 31  │ LF   │ unr  │ deg  │ deg  │ WD   │ 676.848 │ 198.409 │ 488   │ 8.98157 │\n",
       "│ 32  │ LF   │ unr  │ deg  │ deg  │ NW   │ 683.831 │ 197.074 │ 491   │ 8.89382 │"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat = @transform(dat,\n",
    "                 F = levels!(:F, [\"HF\", \"LF\"]),\n",
    "                 P = levels!(:P, [\"rel\", \"unr\"]),\n",
    "                 Q = levels!(:Q, [\"clr\", \"deg\"]),\n",
    "                lQ = levels!(:lQ, [\"clr\", \"deg\"]),\n",
    "                lT = levels!(:lT, [\"WD\", \"NW\"]));\n",
    "\n",
    "cellmeans = by(dat, [:F, :P, :Q, :lQ, :lT], \n",
    "            meanRT = :rt => mean, sdRT = :rt => std, n = :rt => length,\n",
    "            semean = :rt => x -> std(x)/sqrt(length(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complex LMM\n",
    "\n",
    "This is *not* the maximal factorial LMM because we do not include interaction terms and associated correlation parameters in the RE structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cntrsts = merge(\n",
    "    Dict(index => EffectsCoding() for index in (:F, :P, :Q, :lQ, :lT)),\n",
    "    Dict(index => Grouping() for index in (:Subj, :Item)),\n",
    ");\n",
    "\n",
    "m1form = @formula (-1000/rt) ~ 1+F*P*Q*lQ*lT +\n",
    "                              (1+F+P+Q+lQ+lT | Subj) +\n",
    "                              (1+  P+Q+lQ+lT | Item);\n",
    "cmplxLMM = fit(MixedModel, m1form, dat, contrasts=cntrsts);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variance components:\n",
       "            Column      Variance      Std.Dev.    Corr.\n",
       "Item     (Intercept)  0.003202035086 0.056586527\n",
       "         P: unr       0.000129363970 0.011373828 -0.05\n",
       "         Q: deg       0.000159100613 0.012613509 -0.36 +0.38\n",
       "         lQ: deg      0.000034951970 0.005912019 -0.37 +0.02 +0.03\n",
       "         lT: NW       0.000157413709 0.012546462 +0.11 -0.87 -0.01 -0.35\n",
       "Subj     (Intercept)  0.030558963672 0.174811223\n",
       "         F: LF        0.000028917819 0.005377529 -0.44\n",
       "         P: unr       0.000129382006 0.011374621 -0.35 +0.99\n",
       "         Q: deg       0.000788337211 0.028077343 -0.41 +0.71 +0.70\n",
       "         lQ: deg      0.000115295913 0.010737593 -0.06 +0.16 +0.16 +0.58\n",
       "         lT: NW       0.001045670820 0.032336834 -0.26 -0.02 -0.05 +0.37 +0.50\n",
       "Residual              0.085716454639 0.292773726\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VarCorr(cmplxLMM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Item = \n",
       "Principal components based on correlation matrix\n",
       "  1.0     ⋅      ⋅      ⋅     ⋅ \n",
       " -0.05   1.0     ⋅      ⋅     ⋅ \n",
       " -0.36   0.38   1.0     ⋅     ⋅ \n",
       " -0.37   0.02   0.03   1.0    ⋅ \n",
       "  0.11  -0.87  -0.01  -0.35  1.0\n",
       "Normalized cumulative variances:\n",
       "[0.4211, 0.6855, 0.9048, 1.0, 1.0]\n",
       "Component loadings\n",
       " -0.3    0.67  -0.02   0.67  -0.07\n",
       "  0.6    0.38   0.21  -0.05   0.67\n",
       "  0.31  -0.34   0.7    0.47  -0.28\n",
       "  0.31  -0.41  -0.63   0.55   0.2\n",
       " -0.6   -0.34   0.27   0.15   0.66, Subj = \n",
       "Principal components based on correlation matrix\n",
       "  1.0     ⋅      ⋅     ⋅     ⋅    ⋅ \n",
       " -0.44   1.0     ⋅     ⋅     ⋅    ⋅ \n",
       " -0.35   0.99   1.0    ⋅     ⋅    ⋅ \n",
       " -0.41   0.71   0.7   1.0    ⋅    ⋅ \n",
       " -0.06   0.16   0.16  0.58  1.0   ⋅ \n",
       " -0.26  -0.02  -0.05  0.37  0.5  1.0\n",
       "Normalized cumulative variances:\n",
       "[0.5104, 0.7663, 0.9109, 0.9725, 1.0, 1.0]\n",
       "Component loadings\n",
       " -0.33  -0.02  -0.83  -0.43   0.08   0.08\n",
       "  0.51   0.34  -0.08  -0.17  -0.27   0.72\n",
       "  0.5    0.35  -0.18  -0.23  -0.27  -0.69\n",
       "  0.52  -0.14  -0.15   0.05   0.83   0.0\n",
       "  0.28  -0.56  -0.41   0.54  -0.38  -0.0\n",
       "  0.18  -0.66   0.28  -0.66  -0.14  -0.0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmplxLMM.PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variance-covariance matrix of random-effect structure suggests overparameterization\n",
    "for both subject-related and item-related components.\n",
    "\n",
    "We don't look at fixed effects before model selection.\n",
    "\n",
    "### VCs and CPs\n",
    "\n",
    "We can also look separately at item- and subj-related VPs and CPs at a different level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5×5 LinearAlgebra.LowerTriangular{Float64,Array{Float64,2}}:\n",
       "  0.193277      ⋅            ⋅            ⋅          ⋅ \n",
       " -0.00202368   0.0387958     ⋅            ⋅          ⋅ \n",
       " -0.0155872    0.0154923    0.0370561     ⋅          ⋅ \n",
       " -0.00746083   3.41629e-6  -0.00242281   0.0186072   ⋅ \n",
       "  0.00490163  -0.0370277    0.0171984   -0.012066   0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first(cmplxLMM.λ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VP is zero for last diagonal entry; not supported by data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6×6 LinearAlgebra.LowerTriangular{Float64,Array{Float64,2}}:\n",
       "  0.597086      ⋅           ⋅          ⋅          ⋅           ⋅ \n",
       " -0.00815559   0.0164576    ⋅          ⋅          ⋅           ⋅ \n",
       " -0.0134575    0.036446    0.0         ⋅          ⋅           ⋅ \n",
       " -0.0392197    0.0570409  -0.0662138  0.0045742   ⋅           ⋅ \n",
       " -0.00202532   0.0056597  -0.0229463  0.0274795  0.00522481   ⋅ \n",
       " -0.028371    -0.0168555  -0.0562006  0.0137443  0.0756871   0.0451023"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last(cmplxLMM.λ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-correlation parameter LMM (factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variance components:\n",
       "            Column      Variance      Std.Dev.     Corr.\n",
       "Item     (Intercept)  0.003202763157 0.0565929603\n",
       "         P: unr       0.000072375973 0.0085074070   .  \n",
       "         Q: deg       0.000147845307 0.0121591656   .     .  \n",
       "         lQ: deg      0.000015850793 0.0039813055   .     .     .  \n",
       "         lT: NW       0.000116383805 0.0107881326   .     .     .     .  \n",
       "Subj     (Intercept)  0.030610471888 0.1749584862\n",
       "         F: LF        0.000015560260 0.0039446496   .  \n",
       "         P: unr       0.000099560396 0.0099779956   .     .  \n",
       "         Q: deg       0.000773363413 0.0278094123   .     .     .  \n",
       "         lQ: deg      0.000119128505 0.0109146005   .     .     .     .  \n",
       "         lT: NW       0.001060759505 0.0325693031   .     .     .     .     .  \n",
       "Residual              0.085882836483 0.2930577358\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2form = @formula (-1000/rt) ~ 1 + F*P*Q*lQ*lT +\n",
    "                               zerocorr(1+F+P+Q+lQ+lT | Subj) +\n",
    "                               zerocorr(1  +P+Q+lQ+lT | Item);\n",
    "\n",
    "zcpLMM = fit(LinearMixedModel, m2form, dat, contrasts=cntrsts);\n",
    "VarCorr(zcpLMM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variance components:\n",
       "            Column      Variance      Std.Dev.     Corr.\n",
       "Item     (Intercept)  0.003202763157 0.0565929603\n",
       "         P: unr       0.000072375973 0.0085074070   .  \n",
       "         Q: deg       0.000147845307 0.0121591656   .     .  \n",
       "         lQ: deg      0.000015850793 0.0039813055   .     .     .  \n",
       "         lT: NW       0.000116383805 0.0107881326   .     .     .     .  \n",
       "Subj     (Intercept)  0.030610471888 0.1749584862\n",
       "         F: LF        0.000015560260 0.0039446496   .  \n",
       "         P: unr       0.000099560396 0.0099779956   .     .  \n",
       "         Q: deg       0.000773363413 0.0278094123   .     .     .  \n",
       "         lQ: deg      0.000119128505 0.0109146005   .     .     .     .  \n",
       "         lT: NW       0.001060759505 0.0325693031   .     .     .     .     .  \n",
       "Residual              0.085882836483 0.2930577358\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2form_b = @formula (-1000/rt) ~ 1 + F*P*Q*lQ*lT +\n",
    "        (1 |Subj) + (0 +F | Subj) + (0 + P | Subj) + (0 + Q | Subj) + (0 + lQ | Subj) + (0 + lT | Subj) +\n",
    "        (1 |Item) +               + (0 + P | Item) + (0 + Q | Item) + (0 + lQ | Item) + (0 + lT | Item);\n",
    "\n",
    "zcpLMM_b = fit(LinearMixedModel, m2form_b, dat, contrasts=cntrsts);\n",
    "VarCorr(zcpLMM_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VCs and CPs\n",
    "\n",
    "Look ok. It might be a good idea to prune the LMM. \n",
    "\n",
    "## Zero-correlation parameter LMM (indicators)\n",
    "\n",
    "An alternative solution is to extract the indicators of contrasts from the design matrix. Sometimes RE structures are more conveniently specified with indicator variables (i.e., @ level of contrasts) than factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>f</th><th>p</th><th>q</th><th>lq</th><th>lt</th></tr><tr><th></th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th><th>Int64</th></tr></thead><tbody><p>10 rows × 5 columns</p><tr><th>1</th><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td></tr><tr><th>2</th><td>-1</td><td>1</td><td>-1</td><td>1</td><td>-1</td></tr><tr><th>3</th><td>-1</td><td>-1</td><td>-1</td><td>1</td><td>1</td></tr><tr><th>4</th><td>-1</td><td>-1</td><td>1</td><td>1</td><td>1</td></tr><tr><th>5</th><td>-1</td><td>1</td><td>1</td><td>1</td><td>-1</td></tr><tr><th>6</th><td>-1</td><td>-1</td><td>-1</td><td>1</td><td>-1</td></tr><tr><th>7</th><td>-1</td><td>-1</td><td>1</td><td>1</td><td>1</td></tr><tr><th>8</th><td>1</td><td>1</td><td>1</td><td>-1</td><td>1</td></tr><tr><th>9</th><td>1</td><td>1</td><td>-1</td><td>1</td><td>-1</td></tr><tr><th>10</th><td>-1</td><td>-1</td><td>-1</td><td>1</td><td>1</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccc}\n",
       "\t& f & p & q & lq & lt\\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Int64 & Int64 & Int64 & Int64\\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & 1 & 1 & 1 & 1 \\\\\n",
       "\t2 & -1 & 1 & -1 & 1 & -1 \\\\\n",
       "\t3 & -1 & -1 & -1 & 1 & 1 \\\\\n",
       "\t4 & -1 & -1 & 1 & 1 & 1 \\\\\n",
       "\t5 & -1 & 1 & 1 & 1 & -1 \\\\\n",
       "\t6 & -1 & -1 & -1 & 1 & -1 \\\\\n",
       "\t7 & -1 & -1 & 1 & 1 & 1 \\\\\n",
       "\t8 & 1 & 1 & 1 & -1 & 1 \\\\\n",
       "\t9 & 1 & 1 & -1 & 1 & -1 \\\\\n",
       "\t10 & -1 & -1 & -1 & 1 & 1 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "10×5 DataFrame\n",
       "│ Row │ f     │ p     │ q     │ lq    │ lt    │\n",
       "│     │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64\u001b[39m │ \u001b[90mInt64\u001b[39m │\n",
       "├─────┼───────┼───────┼───────┼───────┼───────┤\n",
       "│ 1   │ 1     │ 1     │ 1     │ 1     │ 1     │\n",
       "│ 2   │ -1    │ 1     │ -1    │ 1     │ -1    │\n",
       "│ 3   │ -1    │ -1    │ -1    │ 1     │ 1     │\n",
       "│ 4   │ -1    │ -1    │ 1     │ 1     │ 1     │\n",
       "│ 5   │ -1    │ 1     │ 1     │ 1     │ -1    │\n",
       "│ 6   │ -1    │ -1    │ -1    │ 1     │ -1    │\n",
       "│ 7   │ -1    │ -1    │ 1     │ 1     │ 1     │\n",
       "│ 8   │ 1     │ 1     │ 1     │ -1    │ 1     │\n",
       "│ 9   │ 1     │ 1     │ -1    │ 1     │ -1    │\n",
       "│ 10  │ -1    │ -1    │ -1    │ 1     │ 1     │"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm = Int.(cmplxLMM.X);  \n",
    "\n",
    "dat = @linq dat |>\n",
    "       transform(f = mm[:, 2],\n",
    "                 p = mm[:, 3],\n",
    "                 q = mm[:, 4],\n",
    "                lq = mm[:, 5],\n",
    "                lt = mm[:, 6]);\n",
    "\n",
    "dat[1:10, 10:14]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take out correlation parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variance components:\n",
       "            Column      Variance      Std.Dev.     Corr.\n",
       "Item     (Intercept)  0.003202763157 0.0565929603\n",
       "         p            0.000072375973 0.0085074070   .  \n",
       "         q            0.000147845307 0.0121591656   .     .  \n",
       "         lq           0.000015850793 0.0039813055   .     .     .  \n",
       "         lt           0.000116383805 0.0107881326   .     .     .     .  \n",
       "Subj     (Intercept)  0.030610471888 0.1749584862\n",
       "         f            0.000015560260 0.0039446496   .  \n",
       "         p            0.000099560396 0.0099779956   .     .  \n",
       "         q            0.000773363413 0.0278094123   .     .     .  \n",
       "         lq           0.000119128505 0.0109146005   .     .     .     .  \n",
       "         lt           0.001060759505 0.0325693031   .     .     .     .     .  \n",
       "Residual              0.085882836483 0.2930577358\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2form_c = @formula (-1000/rt) ~ 1 + f*p*q*lq*lt +\n",
    " (1 | Subj) + (0+f | Subj) + (0+p | Subj) + (0+q | Subj) + (0+lq | Subj) + (0+lt | Subj) +\n",
    " (1 | Item) +                (0+p | Item) + (0+q | Item) + (0+lq | Item) + (0+lt | Item);\n",
    "\n",
    "zcpLMM_c = fit(LinearMixedModel, m2form_c, dat, contrasts=cntrsts);\n",
    "VarCorr(zcpLMM_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variance components:\n",
       "            Column      Variance      Std.Dev.     Corr.\n",
       "Item     (Intercept)  0.003202763157 0.0565929603\n",
       "         P: unr       0.000072375973 0.0085074070   .  \n",
       "         Q: deg       0.000147845307 0.0121591656   .     .  \n",
       "         lQ: deg      0.000015850793 0.0039813055   .     .     .  \n",
       "         lT: NW       0.000116383805 0.0107881326   .     .     .     .  \n",
       "Subj     (Intercept)  0.030610471888 0.1749584862\n",
       "         F: LF        0.000015560260 0.0039446496   .  \n",
       "         P: unr       0.000099560396 0.0099779956   .     .  \n",
       "         Q: deg       0.000773363413 0.0278094123   .     .     .  \n",
       "         lQ: deg      0.000119128505 0.0109146005   .     .     .     .  \n",
       "         lT: NW       0.001060759505 0.0325693031   .     .     .     .     .  \n",
       "Residual              0.085882836483 0.2930577358\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2form_d = @formula (-1000/rt) ~ 1 + f*p*q*lq*lt +\n",
    "                               zerocorr(1+f+p+q+lq+lt | Subj) +\n",
    "                               zerocorr(1  +p+q+lq+lt | Item);\n",
    "\n",
    "zcpLMM_d = fit(LinearMixedModel, m2form_d, dat, contrasts=cntrsts);\n",
    "VarCorr(zcpLMM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>dof</th><th>deviance</th><th>AIC</th><th>AICc</th><th>BIC</th></tr><tr><th></th><th>Int64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>5 rows × 5 columns</p><tr><th>1</th><td>69</td><td>7147.92</td><td>7285.92</td><td>7286.51</td><td>7817.61</td></tr><tr><th>2</th><td>44</td><td>7188.49</td><td>7276.49</td><td>7276.73</td><td>7615.54</td></tr><tr><th>3</th><td>44</td><td>7188.49</td><td>7276.49</td><td>7276.73</td><td>7615.54</td></tr><tr><th>4</th><td>44</td><td>7188.49</td><td>7276.49</td><td>7276.73</td><td>7615.54</td></tr><tr><th>5</th><td>44</td><td>7188.49</td><td>7276.49</td><td>7276.73</td><td>7615.54</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccc}\n",
       "\t& dof & deviance & AIC & AICc & BIC\\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Float64 & Float64 & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 69 & 7147.92 & 7285.92 & 7286.51 & 7817.61 \\\\\n",
       "\t2 & 44 & 7188.49 & 7276.49 & 7276.73 & 7615.54 \\\\\n",
       "\t3 & 44 & 7188.49 & 7276.49 & 7276.73 & 7615.54 \\\\\n",
       "\t4 & 44 & 7188.49 & 7276.49 & 7276.73 & 7615.54 \\\\\n",
       "\t5 & 44 & 7188.49 & 7276.49 & 7276.73 & 7615.54 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "5×5 DataFrame\n",
       "│ Row │ dof   │ deviance │ AIC     │ AICc    │ BIC     │\n",
       "│     │ \u001b[90mInt64\u001b[39m │ \u001b[90mFloat64\u001b[39m  │ \u001b[90mFloat64\u001b[39m │ \u001b[90mFloat64\u001b[39m │ \u001b[90mFloat64\u001b[39m │\n",
       "├─────┼───────┼──────────┼─────────┼─────────┼─────────┤\n",
       "│ 1   │ 69    │ 7147.92  │ 7285.92 │ 7286.51 │ 7817.61 │\n",
       "│ 2   │ 44    │ 7188.49  │ 7276.49 │ 7276.73 │ 7615.54 │\n",
       "│ 3   │ 44    │ 7188.49  │ 7276.49 │ 7276.73 │ 7615.54 │\n",
       "│ 4   │ 44    │ 7188.49  │ 7276.49 │ 7276.73 │ 7615.54 │\n",
       "│ 5   │ 44    │ 7188.49  │ 7276.49 │ 7276.73 │ 7615.54 │"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mods = [cmplxLMM, zcpLMM, zcpLMM_b, zcpLMM_c, zcpLMM_d];\n",
    "gof_summary = DataFrame(dof=dof.(mods), deviance=deviance.(mods),\n",
    "              AIC = aic.(mods), AICc = aicc.(mods), BIC = bic.(mods))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are identical for the three versions of `zcpLMM`.  AIC and BIC suggest to go with the `zcpLMM`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model Formulae\n",
       "1: :(-1000 / rt) ~ 1 + F + P + Q + lQ + lT + F & P + F & Q + P & Q + F & lQ + P & lQ + Q & lQ + F & lT + P & lT + Q & lT + lQ & lT + F & P & Q + F & P & lQ + F & Q & lQ + P & Q & lQ + F & P & lT + F & Q & lT + P & Q & lT + F & lQ & lT + P & lQ & lT + Q & lQ & lT + F & P & Q & lQ + F & P & Q & lT + F & P & lQ & lT + F & Q & lQ & lT + P & Q & lQ & lT + F & P & Q & lQ & lT + MixedModels.ZeroCorr((1 + F + P + Q + lQ + lT | Subj)) + MixedModels.ZeroCorr((1 + P + Q + lQ + lT | Item))\n",
       "2: :(-1000 / rt) ~ 1 + F + P + Q + lQ + lT + F & P + F & Q + P & Q + F & lQ + P & lQ + Q & lQ + F & lT + P & lT + Q & lT + lQ & lT + F & P & Q + F & P & lQ + F & Q & lQ + P & Q & lQ + F & P & lT + F & Q & lT + P & Q & lT + F & lQ & lT + P & lQ & lT + Q & lQ & lT + F & P & Q & lQ + F & P & Q & lT + F & P & lQ & lT + F & Q & lQ & lT + P & Q & lQ & lT + F & P & Q & lQ & lT + (1 + F + P + Q + lQ + lT | Subj) + (1 + P + Q + lQ + lT | Item)\n",
       "──────────────────────────────────────────────────\n",
       "     model-dof   deviance       χ²  χ²-dof  P(>χ²)\n",
       "──────────────────────────────────────────────────\n",
       "[1]         44  7188.4894                         \n",
       "[2]         69  7147.9223  40.5671      25  0.0255\n",
       "──────────────────────────────────────────────────"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MixedModels.likelihoodratiotest(cmplxLMM, zcpLMM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A zerocorrelation-parameter pecularity of lme4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@rput dat;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complex LMM with correlation parameters (factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: RCall.jl: Loading required package: Matrix\n",
      "└ @ RCall /Users/reinholdkliegl/.julia/packages/RCall/Qzssx/src/io.jl:160\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RObject{S4Sxp}\n",
       "Linear mixed model fit by maximum likelihood  ['lmerMod']\n",
       "Formula: (-1000/rt) ~ 1 + F + P + (1 + F + P | Subj)\n",
       "   Data: dat\n",
       "      AIC       BIC    logLik  deviance  df.resid \n",
       " 8012.304  8089.360 -3996.152  7992.304     16399 \n",
       "Random effects:\n",
       " Groups   Name        Std.Dev. Corr       \n",
       " Subj     (Intercept) 0.17563             \n",
       "          F1          0.00558  -0.30      \n",
       "          P1          0.01200  -0.41  0.99\n",
       " Residual             0.30553             \n",
       "Number of obs: 16409, groups:  Subj, 73\n",
       "Fixed Effects:\n",
       "(Intercept)           F1           P1  \n",
       "   -1.63965      0.01831      0.01868  \n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R\"\"\"\n",
    "library(lme4)\n",
    "contrasts(dat$F) <- -contr.sum(2)\n",
    "contrasts(dat$P) <- -contr.sum(2)\n",
    "m1 <- lmer((-1000/rt) ~ 1 + F + P + (1 + F + P | Subj), \n",
    "          dat, REML=FALSE, control=lmerControl(calc.derivs=FALSE))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complex LMM with correlation parameters (indicators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RObject{S4Sxp}\n",
       "Linear mixed model fit by maximum likelihood  ['lmerMod']\n",
       "Formula: (-1000/rt) ~ 1 + f + p + (1 + f + p | Subj)\n",
       "   Data: dat\n",
       "      AIC       BIC    logLik  deviance  df.resid \n",
       " 8012.304  8089.360 -3996.152  7992.304     16399 \n",
       "Random effects:\n",
       " Groups   Name        Std.Dev. Corr       \n",
       " Subj     (Intercept) 0.17563             \n",
       "          f           0.00558  -0.30      \n",
       "          p           0.01200  -0.41  0.99\n",
       " Residual             0.30553             \n",
       "Number of obs: 16409, groups:  Subj, 73\n",
       "Fixed Effects:\n",
       "(Intercept)            f            p  \n",
       "   -1.63965      0.01831      0.01868  \n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R\"\"\"\n",
    "head(dat)\n",
    "m1 <- lmer((-1000/rt) ~ 1 + f + p + (1 + f + p | Subj), \n",
    "           dat, REML=FALSE, control=lmerControl(calc.derivs=FALSE))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zerocorr LMM  (indicators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RObject{S4Sxp}\n",
       "Linear mixed model fit by maximum likelihood  ['lmerMod']\n",
       "Formula: (-1000/rt) ~ 1 + f + p + (1 | Subj) + (0 + f | Subj) + (0 + p |  \n",
       "    Subj)\n",
       "   Data: dat\n",
       "      AIC       BIC    logLik  deviance  df.resid \n",
       " 8011.503  8065.442 -3998.752  7997.503     16402 \n",
       "Random effects:\n",
       " Groups   Name        Std.Dev. \n",
       " Subj     (Intercept) 0.1757587\n",
       " Subj.1   f           0.0002314\n",
       " Subj.2   p           0.0117002\n",
       " Residual             0.3055957\n",
       "Number of obs: 16409, groups:  Subj, 73\n",
       "Fixed Effects:\n",
       "(Intercept)            f            p  \n",
       "   -1.63963      0.01831      0.01866  \n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R\"\"\"\n",
    "m1 <- lmer((-1000/rt) ~ 1+f+p+ (1 | Subj) + (0+f | Subj) +  (0+p | Subj), \n",
    "            dat, REML=FALSE, control=lmerControl(calc.derivs=FALSE));\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zerocorr LMM - double-bar syntax (indicators) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RObject{S4Sxp}\n",
       "Linear mixed model fit by maximum likelihood  ['lmerMod']\n",
       "Formula: (-1000/rt) ~ 1 + f + p + ((1 | Subj) + (0 + f | Subj) + (0 +  \n",
       "    p | Subj))\n",
       "   Data: dat\n",
       "      AIC       BIC    logLik  deviance  df.resid \n",
       " 8011.503  8065.442 -3998.752  7997.503     16402 \n",
       "Random effects:\n",
       " Groups   Name        Std.Dev. \n",
       " Subj     (Intercept) 0.1757587\n",
       " Subj.1   f           0.0002314\n",
       " Subj.2   p           0.0117002\n",
       " Residual             0.3055957\n",
       "Number of obs: 16409, groups:  Subj, 73\n",
       "Fixed Effects:\n",
       "(Intercept)            f            p  \n",
       "   -1.63963      0.01831      0.01866  \n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R\"\"\"\n",
    "m1 <- lmer((-1000/rt) ~ 1 + f + p + (1 + f + p || Subj), \n",
    "           dat, REML=FALSE, control=lmerControl(calc.derivs=FALSE))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zerocorr LMM - double-bar syntax (factors) - does not return expected results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RObject{S4Sxp}\n",
       "Linear mixed model fit by maximum likelihood  ['lmerMod']\n",
       "Formula: (-1000/rt) ~ 1 + F + P + ((1 | Subj) + (0 + F | Subj) + (0 +  \n",
       "    P | Subj))\n",
       "   Data: dat\n",
       "      AIC       BIC    logLik  deviance  df.resid \n",
       " 8016.062  8100.824 -3997.031  7994.062     16398 \n",
       "Random effects:\n",
       " Groups   Name        Std.Dev. Corr\n",
       " Subj     (Intercept) 0.13429      \n",
       " Subj.1   FHF         0.08828      \n",
       "          FLF         0.08438  1.00\n",
       " Subj.2   Prel        0.08420      \n",
       "          Punr        0.06106  1.00\n",
       " Residual             0.30559      \n",
       "Number of obs: 16409, groups:  Subj, 73\n",
       "Fixed Effects:\n",
       "(Intercept)           F1           P1  \n",
       "   -1.63965      0.01831      0.01867  \n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R\"\"\"\n",
    "m2 <- lmer((-1000/rt) ~ 1 + F + P + (1 + F + P || Subj), \n",
    "            dat, REML=FALSE, control=lmerControl(calc.derivs=FALSE))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zerocorr LMM  -  default syntax (factors) -- does not return expected results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RObject{S4Sxp}\n",
       "Linear mixed model fit by maximum likelihood  ['lmerMod']\n",
       "Formula: (-1000/rt) ~ 1 + F + P + (1 | Subj) + (0 + F | Subj) + (0 + P |  \n",
       "    Subj)\n",
       "   Data: dat\n",
       "      AIC       BIC    logLik  deviance  df.resid \n",
       " 8016.062  8100.824 -3997.031  7994.062     16398 \n",
       "Random effects:\n",
       " Groups   Name        Std.Dev. Corr\n",
       " Subj     (Intercept) 0.13429      \n",
       " Subj.1   FHF         0.08828      \n",
       "          FLF         0.08438  1.00\n",
       " Subj.2   Prel        0.08420      \n",
       "          Punr        0.06106  1.00\n",
       " Residual             0.30559      \n",
       "Number of obs: 16409, groups:  Subj, 73\n",
       "Fixed Effects:\n",
       "(Intercept)           F1           P1  \n",
       "   -1.63965      0.01831      0.01867  \n"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R\"\"\"\n",
    "m1 <- lmer((-1000/rt) ~ 1 + F + P + (1 | Subj) + (0 + F | Subj) + (0 + P | Subj), \n",
    "           dat, REML=FALSE, control=lmerControl(calc.derivs=FALSE))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LRT favors the complex LMM, but not that  χ² < 2*(χ²-dof). \n",
    "\n",
    "## A replication of MRK17 LMM\n",
    "\n",
    "### LMM with indicator variables \n",
    "\n",
    "Replication of final LMM in Masson and Kliegl (2013, Table 1) as well as reproduction of final lme4-based LMM in Masson et al. (2017, Figure 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variance components:\n",
       "            Column      Variance     Std.Dev.    Corr.\n",
       "Item     (Intercept)  0.00320564078 0.056618378\n",
       "         p            0.00006688990 0.008178625   .  \n",
       "Subj     (Intercept)  0.03061639307 0.174975407\n",
       "         q            0.00076244699 0.027612443 -0.42\n",
       "         lt           0.00106206684 0.032589367   .     .  \n",
       "Residual              0.08640808393 0.293952520\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3form = @formula (-1000/rt) ~ 1 + f*p*q*lq*lt +\n",
    "        (1+q | Subj) + (0+lt | Subj) + (1 | Item) + (0 + p | Item) ;\n",
    "mrk17_LMM = fit(LinearMixedModel, m3form, dat, contrasts=cntrsts);\n",
    "\n",
    "VarCorr(mrk17_LMM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LMM with factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variance components:\n",
       "            Column      Variance     Std.Dev.    Corr.\n",
       "Item     (Intercept)  0.00320564078 0.056618378\n",
       "         P: unr       0.00006688990 0.008178625   .  \n",
       "Subj     (Intercept)  0.03061639307 0.174975407\n",
       "         Q: deg       0.00076244699 0.027612443 -0.42\n",
       "         lT: NW       0.00106206684 0.032589367   .     .  \n",
       "Residual              0.08640808393 0.293952520\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3form_b = @formula (-1000/rt) ~ 1 + F*P*Q*lQ*lT +\n",
    "        (1+Q | Subj) + zerocorr(0+lT | Subj) + zerocorr(1 + P | Item) ;\n",
    "mrk17_LMM_b = fit(LinearMixedModel, m3form_b, dat, contrasts=cntrsts);\n",
    "\n",
    "VarCorr(mrk17_LMM_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is the correlation parameter significant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variance components:\n",
       "            Column      Variance     Std.Dev.    Corr.\n",
       "Item     (Intercept)  0.00320752804 0.056635043\n",
       "         P: unr       0.00006803353 0.008248244   .  \n",
       "Subj     (Intercept)  0.03062344020 0.174995543\n",
       "         Q: deg       0.00076344621 0.027630530   .  \n",
       "         lT: NW       0.00106532575 0.032639328   .     .  \n",
       "Residual              0.08640533704 0.293947847\n"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove single CP for nested LMMs\n",
    "m4form = @formula (-1000/rt) ~ 1 + f*p*q*lq*lt +\n",
    "        zerocorr(1+Q + lT | Subj)+ zerocorr(1 + P | Item) ;\n",
    "rdcdLMM = fit(LinearMixedModel, m4form, dat, contrasts=cntrsts);\n",
    "VarCorr(rdcdLMM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model Formulae\n",
       "1: :(-1000 / rt) ~ 1 + f + p + q + lq + lt + f & p + f & q + p & q + f & lq + p & lq + q & lq + f & lt + p & lt + q & lt + lq & lt + f & p & q + f & p & lq + f & q & lq + p & q & lq + f & p & lt + f & q & lt + p & q & lt + f & lq & lt + p & lq & lt + q & lq & lt + f & p & q & lq + f & p & q & lt + f & p & lq & lt + f & q & lq & lt + p & q & lq & lt + f & p & q & lq & lt + MixedModels.ZeroCorr((1 + Q + lT | Subj)) + MixedModels.ZeroCorr((1 + P | Item))\n",
       "2: :(-1000 / rt) ~ 1 + f + p + q + lq + lt + f & p + f & q + p & q + f & lq + p & lq + q & lq + f & lt + p & lt + q & lt + lq & lt + f & p & q + f & p & lq + f & q & lq + p & q & lq + f & p & lt + f & q & lt + p & q & lt + f & lq & lt + p & lq & lt + q & lq & lt + f & p & q & lq + f & p & q & lt + f & p & lq & lt + f & q & lq & lt + p & q & lq & lt + f & p & q & lq & lt + (1 + q | Subj) + (0 + lt | Subj) + (1 | Item) + (0 + p | Item)\n",
       "─────────────────────────────────────────────────\n",
       "     model-dof   deviance      χ²  χ²-dof  P(>χ²)\n",
       "─────────────────────────────────────────────────\n",
       "[1]         38  7195.8744                        \n",
       "[2]         39  7186.8171  9.0573       1  0.0026\n",
       "─────────────────────────────────────────────────"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MixedModels.likelihoodratiotest(rdcdLMM, mrk17_LMM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation parameter was replicated (i.e., -.42 in MRK17) and significant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>dof</th><th>deviance</th><th>AIC</th><th>AICc</th><th>BIC</th></tr><tr><th></th><th>Int64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>2 rows × 5 columns</p><tr><th>1</th><td>38</td><td>7195.87</td><td>7271.87</td><td>7272.06</td><td>7564.69</td></tr><tr><th>2</th><td>39</td><td>7186.82</td><td>7264.82</td><td>7265.01</td><td>7565.33</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccc}\n",
       "\t& dof & deviance & AIC & AICc & BIC\\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Float64 & Float64 & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & 38 & 7195.87 & 7271.87 & 7272.06 & 7564.69 \\\\\n",
       "\t2 & 39 & 7186.82 & 7264.82 & 7265.01 & 7565.33 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "2×5 DataFrame\n",
       "│ Row │ dof   │ deviance │ AIC     │ AICc    │ BIC     │\n",
       "│     │ \u001b[90mInt64\u001b[39m │ \u001b[90mFloat64\u001b[39m  │ \u001b[90mFloat64\u001b[39m │ \u001b[90mFloat64\u001b[39m │ \u001b[90mFloat64\u001b[39m │\n",
       "├─────┼───────┼──────────┼─────────┼─────────┼─────────┤\n",
       "│ 1   │ 38    │ 7195.87  │ 7271.87 │ 7272.06 │ 7564.69 │\n",
       "│ 2   │ 39    │ 7186.82  │ 7264.82 │ 7265.01 │ 7565.33 │"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mods2 = [rdcdLMM, mrk17_LMM];\n",
    "gof_summary = DataFrame(dof=dof.(mods2), deviance=deviance.(mods2),\n",
    "              AIC = aic.(mods2), AICc = aicc.(mods2), BIC = bic.(mods2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here `dof` or degrees of freedom is the total number of parameters estimated in the model and `deviance` is simply negative twice the log-likelihood at convergence, without a correction for a saturated model.  The AIC/BIC information criteria are on a scale of \"smaller is better\" and all would select `mrk17_LMM` as \"best\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed effects\n",
    "\n",
    "Finally, a look at the fixed effects. The four-factor interaction reported in Masson & Kliegl (2013) was not replicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear mixed model fit by maximum likelihood\n",
      " :(-1000 / rt) ~ 1 + f + p + q + lq + lt + f & p + f & q + p & q + f & lq + p & lq + q & lq + f & lt + p & lt + q & lt + lq & lt + f & p & q + f & p & lq + f & q & lq + p & q & lq + f & p & lt + f & q & lt + p & q & lt + f & lq & lt + p & lq & lt + q & lq & lt + f & p & q & lq + f & p & q & lt + f & p & lq & lt + f & q & lq & lt + p & q & lq & lt + f & p & q & lq & lt + (1 + q | Subj) + (0 + lt | Subj) + (1 | Item) + (0 + p | Item)\n",
      "     logLik        -2 logLik          AIC             BIC       \n",
      " -3.59340856×10³  7.18681711×10³  7.26481711×10³  7.56533494×10³\n",
      "\n",
      "Variance components:\n",
      "            Column      Variance     Std.Dev.    Corr.\n",
      "Item     (Intercept)  0.00320564078 0.056618378\n",
      "         p            0.00006688990 0.008178625   .  \n",
      "Subj     (Intercept)  0.03061639307 0.174975407\n",
      "         q            0.00076244699 0.027612443 -0.42\n",
      "         lt           0.00106206684 0.032589367   .     .  \n",
      "Residual              0.08640808393 0.293952520\n",
      " Number of obs: 16409; levels of grouping factors: 240, 73\n",
      "\n",
      "  Fixed-effects parameters:\n",
      "───────────────────────────────────────────────────────────────\n",
      "                            Coef.  Std. Error       z  Pr(>|z|)\n",
      "───────────────────────────────────────────────────────────────\n",
      "(Intercept)          -1.63743      0.02093     -78.23    <1e-99\n",
      "f                     0.019366     0.00431953    4.48    <1e-5\n",
      "p                     0.0188081    0.0023611     7.97    <1e-14\n",
      "q                     0.042901     0.00396822   10.81    <1e-26\n",
      "lq                    0.00174653   0.00231531    0.75    0.4506\n",
      "lt                    0.00836023   0.00446179    1.87    0.0610\n",
      "f & p                 0.00711249   0.00236168    3.01    0.0026\n",
      "f & q                 0.00141259   0.00230067    0.61    0.5392\n",
      "p & q                -0.00134143   0.00230239   -0.58    0.5601\n",
      "f & lq                0.00105227   0.00232139    0.45    0.6503\n",
      "p & lq                0.00240743   0.00232056    1.04    0.2995\n",
      "q & lq               -0.00759806   0.00231922   -3.28    0.0011\n",
      "f & lt               -0.000536555  0.00231365   -0.23    0.8166\n",
      "p & lt               -2.93345e-5   0.00231751   -0.01    0.9899\n",
      "q & lt               -0.00185533   0.00231773   -0.80    0.4234\n",
      "lq & lt               0.00524632   0.00231608    2.27    0.0235\n",
      "f & p & q            -0.000362238  0.00230273   -0.16    0.8750\n",
      "f & p & lq           -0.00117754   0.00232025   -0.51    0.6118\n",
      "f & q & lq            0.00273698   0.00232283    1.18    0.2387\n",
      "p & q & lq           -0.0039323    0.0023222    -1.69    0.0904\n",
      "f & p & lt            0.00198641   0.00231879    0.86    0.3916\n",
      "f & q & lt           -0.00112585   0.00231657   -0.49    0.6270\n",
      "p & q & lt            0.000261819  0.00231924    0.11    0.9101\n",
      "f & lq & lt           0.00150677   0.00232199    0.65    0.5164\n",
      "p & lq & lt           8.68062e-5   0.00232177    0.04    0.9702\n",
      "q & lq & lt           0.00916752   0.00231827    3.95    <1e-4\n",
      "f & p & q & lq        0.00234443   0.00231978    1.01    0.3122\n",
      "f & p & q & lt        0.0014872    0.00232058    0.64    0.5216\n",
      "f & p & lq & lt      -0.00308766   0.00232145   -1.33    0.1835\n",
      "f & q & lq & lt      -0.00393599   0.00232128   -1.70    0.0900\n",
      "p & q & lq & lt      -0.00202624   0.00232125   -0.87    0.3827\n",
      "f & p & q & lq & lt   0.00144889   0.00231838    0.62    0.5320\n",
      "───────────────────────────────────────────────────────────────"
     ]
    }
   ],
   "source": [
    "show(mrk17_LMM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix \n",
    "\n",
    "## Weave the document in the REPL\n",
    "\n",
    "```\n",
    "julia> using Weave\n",
    "julia> weave(scriptsdir(\"MRK17_spcfctn_slctn.jmd\"), doctype=\"md2html\")\n",
    "```\n",
    "\n",
    "## Switch to jupyter notebook from REPL\n",
    "\n",
    "```\n",
    "julia> using Weave, IJulia\n",
    "julia> convert_doc(scriptsdir(\"MRK17_spcfctn_slctn.jmd\"), projectdir(\"notebooks\",\"MRK17_spcfctn_slctn.ipynb\"))\n",
    "julia> IJulia.notebook(dir=projectdir(\"notebooks\"))\n",
    "```\n",
    "\n",
    "## Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia Version 1.5.1\n",
      "Commit 697e782ab8 (2020-08-25 20:08 UTC)\n",
      "Platform Info:\n",
      "  OS: macOS (x86_64-apple-darwin19.5.0)\n",
      "  CPU: Intel(R) Core(TM) i9-8950HK CPU @ 2.90GHz\n",
      "  WORD_SIZE: 64\n",
      "  LIBM: libopenlibm\n",
      "  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)\n",
      "Environment:\n",
      "  JULIA_EDITOR = \"/Applications/Visual Studio Code.app/Contents/Resources/app/bin/code\"\n",
      "  JULIA_NUM_THREADS = 6\n"
     ]
    }
   ],
   "source": [
    "using InteractiveUtils\n",
    "versioninfo()"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.5.0",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
